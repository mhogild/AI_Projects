from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
import os

# ðŸ” SÃ¦t din OpenAI API-nÃ¸gle (du mÃ¥ gerne sÃ¦tte denne via miljÃ¸variabel i stedet)
os.environ["OPENAI_API_KEY"] = "XX" #Skjult - Du skal vÃ¦re velkommen til at spÃ¸rge efter API hvis du gerne vil teste den :)

# 1. Load gemte embeddings fra Chroma
vectorstore = Chroma(
    persist_directory="./Projekt_1_RAG_Chatbot/chroma_test",
    embedding_function=OpenAIEmbeddings()
)

# 2. Retriever
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

# 3. GPT-model og kÃ¦de
llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.5)

qa = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    return_source_documents=True
)

# 4. Chat loop
while True:
    query = input("\nðŸ” Stil et spÃ¸rgsmÃ¥l om Ã¥rsrapporten (eller skriv 'exit'): ")
    if query.lower() in ["exit", "quit"]:
        break

    result = qa.invoke(query)
    print("\nðŸ’¬ Svar:\n", result['result'])

    print("\nðŸ“„ Kilder:")
    for idx, doc in enumerate(result['source_documents'], 1):
        title = doc.metadata.get("title", "Ukendt afsnit")
        page = doc.metadata.get("page", "ukendt")
        snippet = doc.page_content.strip().replace("\n", " ")
        short_quote = snippet[:40] + ("â€¦" if len(snippet) > 40 else "")

        print(f"- Kilde {idx}")
        print(f"{title} (side: {page})")
        print(f"{short_quote}\n")